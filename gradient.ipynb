{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] 系统找不到指定的路径。: 'E:\\\\code\\\\BiLSTM\\\\BiLSTM\\\\train'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\3356944586.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[1;31m# 遍历文件夹下的每个xlsx文件\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'.xlsx'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m         \u001b[1;31m# print(filename)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 3] 系统找不到指定的路径。: 'E:\\\\code\\\\BiLSTM\\\\BiLSTM\\\\train'"
     ]
    }
   ],
   "source": [
    "# 读训练数据(所有井存一起)，去除坏数据\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# 文件夹路径\n",
    "folder_path = 'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\train'\n",
    "# folder_path = 'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\test'\n",
    "\n",
    "# target_column = [\"DZL\", \"ZRGM\"]\n",
    "all_data = np.array([])\n",
    "\n",
    "# 遍历文件夹下的每个xlsx文件\n",
    "for filename in os.listdir(folder_path):\n",
    "    if filename.endswith('.xlsx'):\n",
    "        # print(filename)\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "        # 读取Excel文件中的第二个表格\n",
    "        xls = pd.ExcelFile(file_path)\n",
    "        sheet_names = xls.sheet_names\n",
    "        if len(sheet_names) > 1:\n",
    "            df = pd.read_excel(file_path, sheet_name=sheet_names[1], header=None)\n",
    "\n",
    "            # 获取第三行数据作为表头\n",
    "            header = df.iloc[2]\n",
    "\n",
    "            # 找到标签为\"XXX\"的列\n",
    "            md_column = header[header == \"DMZKMD\"].index[0]\n",
    "            dzl_column = header[header == \"DZL\"].index[0]\n",
    "            zrgm_column = header[header == \"ZRGM\"].index[0]\n",
    "            gg_column = header[header == \"DMZKGG\"].index[0]\n",
    "            dssc_column = header[header == \"DSSC\"].index[0]\n",
    "            zrdw_column = header[header == \"ZRDW\"].index[0]\n",
    "\n",
    "            # 提取对应列的数据\n",
    "            md_data = df.iloc[3:, md_column].values\n",
    "            dzl_data = df.iloc[3:, dzl_column].values\n",
    "            zrgm_data = df.iloc[3:, zrgm_column].values\n",
    "            gg_data = df.iloc[3:, gg_column].values\n",
    "            dssc_data = df.iloc[3:, dssc_column].values\n",
    "            zrdw_data = df.iloc[3:, zrdw_column].values\n",
    "\n",
    "            # 清洗数据：将列转换为数值类型\n",
    "            md_data = pd.to_numeric(md_data, errors='coerce')\n",
    "            dzl_data = pd.to_numeric(dzl_data, errors='coerce')\n",
    "            zrgm_data = pd.to_numeric(zrgm_data, errors='coerce')\n",
    "            gg_data = pd.to_numeric(gg_data, errors='coerce')\n",
    "            dssc_data = pd.to_numeric(dssc_data, errors='coerce')\n",
    "            zrdw_data = pd.to_numeric(zrdw_data, errors='coerce')\n",
    "\n",
    "            # 将数据存储到NumPy数组中\n",
    "            well_train_data = []\n",
    "            if len(md_data) > 0 and len(dzl_data) > 0 and len(zrgm_data) > 0 and len(gg_data) > 0 and len(dssc_data) > 0 and len(zrdw_data) > 0:\n",
    "                well_train_data = np.array([md_data, dzl_data, zrgm_data, gg_data, dssc_data, zrdw_data])\n",
    "\n",
    "            # 检测有缺失值的列并创建布尔索引\n",
    "            mask = np.isnan(well_train_data).any(axis=0)\n",
    "            # 使用布尔索引选择不包含缺失值的列\n",
    "            well_train_data = well_train_data[:, ~mask]\n",
    "\n",
    "            # 找到开头和结尾处的\"0\"值所在列\n",
    "            start_indices = 0\n",
    "            end_indices= len(well_train_data[0]) - 1\n",
    "            while start_indices <= end_indices and np.any(well_train_data[:, start_indices] == 0):\n",
    "                start_indices += 1\n",
    "            while end_indices >= start_indices and np.any(well_train_data[:, end_indices] == 0):\n",
    "                end_indices -= 1\n",
    "            min_columns = end_indices - start_indices + 1\n",
    "\n",
    "            # 将剔除开头结尾处\"0\"值的数据存储到新的NumPy数组中\n",
    "            new_well_train_data = []\n",
    "            if start_indices <= end_indices:\n",
    "                for i in range(len(well_train_data)):\n",
    "                    new_well_train_data.append(well_train_data[i][start_indices:end_indices + 1])\n",
    "\n",
    "            new_well_train_data = np.array(new_well_train_data)\n",
    "\n",
    "            if all_data.size == 0:\n",
    "                all_data = new_well_train_data\n",
    "            else:\n",
    "                all_data = np.concatenate((all_data, new_well_train_data), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 数据进行小波变换\n",
    "import numpy as np\n",
    "import pywt\n",
    "\n",
    "reconstructed_all_data = []\n",
    "for data in all_data:\n",
    "    wavelet = 'db4'  # 选择小波基函数，这里使用Haar小波\n",
    "    coeffs = pywt.wavedec(data, wavelet)\n",
    "\n",
    "    # 设置截断级别（保留前N个系数）\n",
    "    truncate_level = 5  # 表示保留到第4级小波系数\n",
    "    coeffs[truncate_level+1:] = [np.zeros_like(coeff) for coeff in coeffs[truncate_level+1:]]\n",
    "\n",
    "    # 进行逆小波变换以重构信号\n",
    "    reconstructed_all_data.append(pywt.waverec(coeffs, wavelet))\n",
    "\n",
    "reconstructed_all_data = np.array(reconstructed_all_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "reconstructed_train_data = reconstructed_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_test_data = reconstructed_all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\3493111821.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfigsize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m12\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m6\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 6\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'原始信号'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 绘制原始信号和重构信号\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(2, 1, 1)\n",
    "plt.plot(all_data[0])\n",
    "plt.title('原始信号')\n",
    "plt.subplot(2, 1, 2)\n",
    "plt.plot(reconstructed_test_data[0])\n",
    "plt.title('重构信号（截断小波系数）')\n",
    "\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# 找测试井每类属性的最大最小值\n",
    "min_vals = []\n",
    "max_vals = []\n",
    "# 遍历每列属性寻找最大最小值\n",
    "for row1, row2 in zip(all_data, reconstructed_all_data):\n",
    "    min_val1 = np.min(row1, axis=0)\n",
    "    min_val2 = np.min(row2, axis=0)\n",
    "    max_val1 = np.max(row1, axis=0)\n",
    "    max_val2 = np.max(row2, axis=0)\n",
    "\n",
    "    min_val = min(min_val1, min_val2)\n",
    "    max_val = max(max_val1, max_val2)\n",
    "\n",
    "    min_vals.append(min_val)\n",
    "    max_vals.append(max_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reconstructed_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\2616573920.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 剔除训练数据中的异常值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnew_all_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mreconstructed_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mrows_to_delete\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_all_train_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reconstructed_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 剔除训练数据中的异常值\n",
    "new_all_train_data = reconstructed_train_data.T\n",
    "rows_to_delete = []\n",
    "num = 0\n",
    "for i in range(new_all_train_data.shape[0]):\n",
    "    if not (min_vals[0] <= new_all_train_data[i, 0] <= max_vals[0]) or not (min_vals[1] <= new_all_train_data[i, 1] <= max_vals[1]) or not (min_vals[2] <= new_all_train_data[i, 2] <= max_vals[2]) or not (min_vals[3] <= new_all_train_data[i, 3] <= max_vals[3]) or not (min_vals[4] <= new_all_train_data[i, 4] <= max_vals[4]) or not (min_vals[5] <= new_all_train_data[i, 5] <= max_vals[5]):\n",
    "        num += 1\n",
    "        rows_to_delete.append(i)\n",
    "\n",
    "\n",
    "new_all_train_data = np.delete(new_all_train_data, rows_to_delete, axis=0)\n",
    "\n",
    "new_all_train_data = new_all_train_data.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'new_all_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\3981720427.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mgray_all_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 遍历每列属性并进行灰度化处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnew_all_train_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[1;31m# 计算灰度化后的值\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgray_column_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mminimum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmax_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mmin_vals\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'new_all_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 训练数据灰度化\n",
    "# 定义灰度尺度\n",
    "g = 512\n",
    "\n",
    "gray_all_train_data = []\n",
    "# 遍历每列属性并进行灰度化处理\n",
    "for i, column_data in enumerate(new_all_train_data):\n",
    "    # 计算灰度化后的值\n",
    "    gray_column_data = np.minimum(np.floor((column_data - min_vals[i]) * g / (max_vals[i] - min_vals[i])), g - 1)\n",
    "\n",
    "    gray_all_train_data.append(gray_column_data)\n",
    "\n",
    "gray_all_train_data = np.array(gray_all_train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AxisError",
     "evalue": "axis 1 is out of bounds for array of dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAxisError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\1173539313.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 计算水平方向上的梯度\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mgradient_all_train_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdiff\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray_all_train_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mdiff\u001b[1;34m(a, n, axis, prepend, append)\u001b[0m\n\u001b[0;32m   1257\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mnd\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1258\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"diff requires input that is at least one dimensional\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1259\u001b[1;33m     \u001b[0maxis\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnormalize_axis_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1260\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1261\u001b[0m     \u001b[0mcombined\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAxisError\u001b[0m: axis 1 is out of bounds for array of dimension 1"
     ]
    }
   ],
   "source": [
    "# 计算水平方向上的梯度\n",
    "gradient_all_train_data = np.diff(gray_all_train_data, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gradient_all_train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\2955146776.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[0mmd_zrdw_glcm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mg\u001b[0m\u001b[1;33m*\u001b[0m\u001b[1;36m2\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mint32\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 15\u001b[1;33m \u001b[0mmd_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_all_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     16\u001b[0m \u001b[0mdzl_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_all_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m \u001b[0mzrgm_column\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgradient_all_train_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'gradient_all_train_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 提取梯度共生矩阵\n",
    "import numpy as np\n",
    "\n",
    "# 存储所有井连接后的梯度共生矩阵\n",
    "all_glcm = []\n",
    "\n",
    "# 遍历灰度化后的两列属性，计算 GLCM\n",
    "# 初始化两条曲线间的梯度共生矩阵\n",
    "md_dzl_glcm = np.zeros((g*2 - 1, g*2 - 1), dtype=np.int32)\n",
    "md_zrgm_glcm = np.zeros((g*2 - 1, g*2 - 1), dtype=np.int32)\n",
    "md_gg_glcm = np.zeros((g*2 - 1, g*2 - 1), dtype=np.int32)\n",
    "md_dssc_glcm = np.zeros((g*2 - 1, g*2 - 1), dtype=np.int32)\n",
    "md_zrdw_glcm = np.zeros((g*2 - 1, g*2 - 1), dtype=np.int32)\n",
    "\n",
    "md_column = gradient_all_train_data[0]\n",
    "dzl_column = gradient_all_train_data[1]\n",
    "zrgm_column = gradient_all_train_data[2]\n",
    "gg_column = gradient_all_train_data[3]\n",
    "dssc_column = gradient_all_train_data[4]\n",
    "zrdw_column = gradient_all_train_data[5]\n",
    "\n",
    "# 提取md和dzl间的梯度共生矩阵\n",
    "for i in range(len(md_column)):\n",
    "    x = int(md_column[i])\n",
    "    y = int(dzl_column[i])\n",
    "\n",
    "    # 确保坐标在范围内\n",
    "    if -g <= x < g and -g <= y < g:\n",
    "        md_dzl_glcm[x + 511, y + 511] += 1\n",
    "\n",
    "# 提取md和zrgm间的梯度共生矩阵\n",
    "for i in range(len(md_column)):\n",
    "    x = int(md_column[i])\n",
    "    y = int(zrgm_column[i])\n",
    "\n",
    "    # 确保坐标在范围内\n",
    "    if -g <= x < g and -g <= y < g:\n",
    "        md_zrgm_glcm[x + 511, y  + 511] += 1\n",
    "\n",
    "# 提取md和gg间的梯度共生矩阵\n",
    "for i in range(len(md_column)):\n",
    "    x = int(md_column[i])\n",
    "    y = int(gg_column[i])\n",
    "\n",
    "    # 确保坐标在范围内\n",
    "    if -g <= x < g and -g <= y < g:\n",
    "        md_gg_glcm[x + 511, y + 511] += 1\n",
    "\n",
    "# 提取md和dssc间的梯度共生矩阵\n",
    "for i in range(len(md_column)):\n",
    "    x = int(md_column[i])\n",
    "    y = int(dssc_column[i])\n",
    "\n",
    "    # 确保坐标在范围内\n",
    "    if -g <= x < g and -g <= y < g:\n",
    "        md_dssc_glcm[x + 511, y + 511] += 1\n",
    "\n",
    "# 提取md和zrdw间的梯度共生矩阵\n",
    "for i in range(len(md_column)):\n",
    "    x = int(md_column[i])\n",
    "    y = int(zrdw_column[i])\n",
    "\n",
    "    # 确保坐标在范围内\n",
    "    if -g <= x < g and -g <= y < g:\n",
    "        md_zrdw_glcm[x + 511, y + 511] += 1\n",
    "\n",
    "# 对 GLCM 进行归一化，以计算概率\n",
    "# dzl_zrgm_glcm_normalized = dzl_zrgm_glcm / np.sum(well_glcm)\n",
    "# well_glcm.append(dzl_zrgm_glcm_normalized)\n",
    "all_glcm.append(md_dzl_glcm)\n",
    "all_glcm.append(md_zrgm_glcm)\n",
    "all_glcm.append(md_gg_glcm)\n",
    "all_glcm.append(md_dssc_glcm)\n",
    "all_glcm.append(md_zrdw_glcm)\n",
    "\n",
    "# all_glcm 现在包含了每两列属性之间的梯度共生矩阵\n",
    "all_glcm = np.array(all_glcm)\n",
    "\n",
    "total = 0\n",
    "# for row in all_glcm[0]:\n",
    "#     print(row)\n",
    "#\n",
    "for i in range(len(all_glcm[1])):\n",
    "    for j in range(len(all_glcm[1][i])):\n",
    "        if all_glcm[1][i][j] != 0:\n",
    "            total += all_glcm[1][i][j]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# 根据梯度共生矩阵提取梯度共生关系\n",
    "import numpy as np\n",
    "\n",
    "# 存储所有井的梯度共生关系\n",
    "all_srm = []\n",
    "for one_glcm in all_glcm:\n",
    "    # 查找每行中最大值所在的列的索引，如果最大值为\"0\"，则返回列索引为\"-512\"\n",
    "    result_indices = []\n",
    "    # 遍历每行\n",
    "    for row in one_glcm:\n",
    "        max_value = np.max(row)\n",
    "        if max_value == 0:\n",
    "            result_indices.append(-512)\n",
    "        else:\n",
    "            max_index = np.argmax(row) - 511\n",
    "            result_indices.append(max_index)\n",
    "    all_srm.append(result_indices)\n",
    "\n",
    "all_srm = np.array(all_srm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "all_srm_t = all_srm.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reconstructed_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\2286695995.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 遍历每列属性并进行灰度梯度化处理\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumn_data\u001b[0m \u001b[1;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreconstructed_test_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumn_data\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'reconstructed_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# 测试数据 x值灰度梯度化\n",
    "gradient_test_data_x = []\n",
    "\n",
    "# 遍历每列属性并进行灰度梯度化处理\n",
    "for i, column_data in enumerate(reconstructed_test_data[1:]):\n",
    "    print(np.min(column_data, axis=0))\n",
    "    print(np.max(column_data, axis=0))\n",
    "    # 计算灰度梯度化后的值\n",
    "    gray_column_data = np.minimum(np.floor((column_data - min_vals[i + 1]) * g / (max_vals[i + 1] - min_vals[i + 1])), g - 1)\n",
    "    gradient_column_data = np.diff(gray_column_data)\n",
    "\n",
    "    gradient_test_data_x.append(gradient_column_data)\n",
    "\n",
    "gradient_test_data_x = np.array(gradient_test_data_x)\n",
    "gradient_test_data_x = gradient_test_data_x.T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\1487272450.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0mcorrelation_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_corr_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m \u001b[0mcorrelation_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m \u001b[0mcorrelation_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorrelation_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "# 测试井y属性灰度梯度值复原\n",
    "# 初始化相关性结果数组\n",
    "correlation_results = []\n",
    "\n",
    "# 遍历数组A中的每一行\n",
    "for row_A in gradient_test_data_x:\n",
    "    max_corr = 512  # 初始化最高相关性为负数\n",
    "    max_corr_index = -512  # 初始化最高相关性的行索引为-1\n",
    "\n",
    "    # 遍历数组B中的每一行\n",
    "    for i, row_B in enumerate(all_srm_t):\n",
    "        # 检查B中的行是否全为-1，如果是则跳过该行\n",
    "        if np.all(row_B == -512):\n",
    "            continue\n",
    "\n",
    "        # 计算两行之间的相关性\n",
    "        corr = np.mean(np.abs(row_A - row_B))\n",
    "        # corr = np.corrcoef(row_A, row_B)[0, 1]\n",
    "        print(corr)\n",
    "\n",
    "        # 如果找到更高的相关性，则更新相关性和行索引\n",
    "        if corr < max_corr:\n",
    "            max_corr = corr\n",
    "            max_corr_index = i - 511\n",
    "\n",
    "    print(\"===========\")\n",
    "\n",
    "    # 将最高相关性的行索引添加到结果数组中\n",
    "    correlation_results.append(max_corr_index)\n",
    "\n",
    "correlation_results.append(correlation_results[-1])\n",
    "correlation_results = np.array(correlation_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 0 is out of bounds for axis 0 with size 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\3031124324.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mgray_test_data_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mmin_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mmax_val\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: index 0 is out of bounds for axis 0 with size 0"
     ]
    }
   ],
   "source": [
    "# 测试数据 y值灰度梯度化\n",
    "gray_test_data_y = []\n",
    "\n",
    "min_val = np.min(all_data[0])\n",
    "max_val = np.max(all_data[0])\n",
    "\n",
    "# 计算灰度化后的值\n",
    "# gray_column_data_y = np.minimum(np.floor((reconstructed_test_data[0] - min_vals[0]) * g / (max_vals[0] - min_vals[0])), g - 1)\n",
    "gray_column_data_y = np.minimum(np.floor((all_data[0] - min_val) * g / (max_val - min_val)), g - 1)\n",
    "gradient_column_data_y = np.diff(gray_column_data_y)\n",
    "gradient_column_data_y = np.append(gradient_column_data_y, gradient_column_data_y[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'E:\\\\code\\\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_DSX.xlsx'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\3731579993.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mfile_path1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_DSX.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mfile_path2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_SBET.xlsx'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mdf1\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mdf2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_excel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_path2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\pandas\\util\\_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m                 )\n\u001b[1;32m--> 311\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    312\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36mread_excel\u001b[1;34m(io, sheet_name, header, names, index_col, usecols, squeeze, dtype, engine, converters, true_values, false_values, skiprows, nrows, na_values, keep_default_na, na_filter, verbose, parse_dates, date_parser, thousands, decimal, comment, skipfooter, convert_float, mangle_dupe_cols, storage_options)\u001b[0m\n\u001b[0;32m    455\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m         \u001b[0mshould_close\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m         \u001b[0mio\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mExcelFile\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mio\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m!=\u001b[0m \u001b[0mio\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m         raise ValueError(\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, path_or_buffer, engine, storage_options)\u001b[0m\n\u001b[0;32m   1374\u001b[0m                 \u001b[0mext\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"xls\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1375\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1376\u001b[1;33m                 ext = inspect_excel_format(\n\u001b[0m\u001b[0;32m   1377\u001b[0m                     \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1378\u001b[0m                 )\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\pandas\\io\\excel\\_base.py\u001b[0m in \u001b[0;36minspect_excel_format\u001b[1;34m(content_or_path, storage_options)\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[0mcontent_or_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mBytesIO\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontent_or_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1249\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1250\u001b[1;33m     with get_handle(\n\u001b[0m\u001b[0;32m   1251\u001b[0m         \u001b[0mcontent_or_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"rb\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstorage_options\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstorage_options\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mis_text\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1252\u001b[0m     ) as handle:\n",
      "\u001b[1;32mD:\\Program\\anaconda3\\lib\\site-packages\\pandas\\io\\common.py\u001b[0m in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m             \u001b[1;31m# Binary mode\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m             \u001b[0mhandle\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mioargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    796\u001b[0m         \u001b[0mhandles\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'E:\\\\code\\\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_DSX.xlsx'"
     ]
    }
   ],
   "source": [
    "# 将灰度复原结果恢复成测井值\n",
    "# 读取保存了灰度复原结果的文件\n",
    "file_path1 = 'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_DSX.xlsx'\n",
    "file_path2 = 'E:\\\\code\\BiLSTM\\\\BiLSTM\\\\res\\\\A2：grey_predict_data_SBET.xlsx'\n",
    "df1 = pd.read_excel(file_path1)\n",
    "df2 = pd.read_excel(file_path2)\n",
    "\n",
    "\n",
    "# 提取第一列的数据到NumPy数组\n",
    "grey_data1 = df1.iloc[:, 0].values\n",
    "grey_data2 = df2.iloc[:, 0].values\n",
    "\n",
    "max_grey_gradient = np.max(gradient_column_data_y)\n",
    "min_grey_gradient = np.min(gradient_column_data_y)\n",
    "\n",
    "\n",
    "# 将梯度复原结果用于曲线复原 (max_vals[0] - min_vals[0]) / g + min_vals[0]\n",
    "recover_column_data_y1 = (grey_data1 +  gradient_column_data_y[:len(grey_data1)]/(max_grey_gradient - min_grey_gradient)) * (3.13 - 1.52) / g + 1.52\n",
    "recover_column_data_y2 = (grey_data2 +  gradient_column_data_y[len(grey_data1):]/(max_grey_gradient - min_grey_gradient)) * (2.55 - 1.35) / g + 1.35 + 0.18\n",
    "\n",
    "wavelet = 'db4'  # 选择小波基函数\n",
    "coeffs1 = pywt.wavedec(recover_column_data_y1, wavelet)\n",
    "coeffs2 = pywt.wavedec(recover_column_data_y2, wavelet)\n",
    "\n",
    "# 设置截断级别（保留前N个系数）\n",
    "truncate_level = 4  # 表示保留到第4级小波系数\n",
    "coeffs1[truncate_level+1:] = [np.zeros_like(coeff) for coeff in coeffs1[truncate_level+1:]]\n",
    "coeffs2[truncate_level+2:] = [np.zeros_like(coeff) for coeff in coeffs2[truncate_level+2:]]\n",
    "\n",
    "# 进行逆小波变换以重构信号\n",
    "recover_column_data_y1 = pywt.waverec(coeffs1, wavelet)[:len(grey_data1)]\n",
    "recover_column_data_y2 = pywt.waverec(coeffs2, wavelet)[:len(grey_data2)]\n",
    "\n",
    "recover_column_data_y = np.concatenate([recover_column_data_y1, recover_column_data_y2])\n",
    "\n",
    "# 绘制原始信号和重构信号\n",
    "plt.figure(figsize=(20, 6))\n",
    "plt.subplot(1, 1, 1)\n",
    "plt.plot(recover_column_data_y, color='b')\n",
    "plt.plot(all_data[0], color='r')\n",
    "\n",
    "# 显示图表\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recover_column_data_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_39716\\1455617255.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m# 创建一个 Pandas 数据框\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[1;34m'Predict'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mrecover_column_data_y\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'True'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mall_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# 指定要保存的 Excel 文件名\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recover_column_data_y' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# 创建一个 Pandas 数据框\n",
    "df = pd.DataFrame({'Predict': recover_column_data_y, 'True': all_data[0]})\n",
    "\n",
    "# 指定要保存的 Excel 文件名\n",
    "excel_file = '../res/gradient_recover_predict_data.xlsx'\n",
    "\n",
    "# 将数据框保存为 Excel 文件\n",
    "df.to_excel(excel_file, index=False)\n",
    "\n",
    "print(\"数据已保存到 Excel 文件:\", excel_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
